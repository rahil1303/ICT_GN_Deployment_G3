Accessible Public Transport Web App for Visually Impaired Users

Build a progressive web application (PWA) using React (with TypeScript) that serves visually impaired users in the Global North. The app must be WCAG 2.1 Level AA–compliant, multilingual (English, Spanish, French), and include these eight high-level functionalities, each clearly surfaced as workflows or tabs. Incorporate specific design choices (layout, color, icons, navigation, onboarding, TTS, voice input, haptic feedback via Vibration API) so that the generated code and structure meet the accessibility and UX requirements.

Technical Stack & Setup
Framework: React with TypeScript, functional components and hooks.

State Management: React Context or Redux for global state (user account, saved routes, tickets, preferences).

Styling: CSS Modules or Styled Components using CSS variables for themes (high-contrast default). Ensure responsive single-column layout.

PWA: Service Worker for offline support (cached assets, saved routes/tickets).

Data Storage:

IndexedDB (via a small wrapper like idb) or localStorage for saved routes, tickets, journey history.

Secure storage for sensitive data if needed (consider encrypting tokens).

APIs & Web Features:

Geolocation API for current location detection.

Fetch for GTFS-RT or mock JSON endpoints.

Web Speech API:

SpeechRecognition for voice input.

SpeechSynthesis for TTS feedback.

Vibration API for haptic cues on supported devices.

Notification API for push-like alerts (with user permission).

Internationalization: react-i18next or similar; resource files for English, Spanish, French. On language change, update TTS voice language.

Accessibility: Semantic HTML elements, ARIA roles/labels, proper focus management, keyboard navigation, logical reading order, supporting screen readers (VoiceOver, TalkBack via mobile browser).

Mock Services & Testing: Provide mock GTFS-RT JSON files and mock endpoints for boarding assistance notifications, missed validation reports, etc. Include instructions for simulating voice input and real-time updates.

Global UI & UX Requirements
Layout

Single-column, responsive design. On narrow viewports, show one panel at a time; on wider viewports, can show side-by-side but ensure reading order remains logical.

Use semantic landmarks: <header>, <main>, <nav>, <section>, <footer>.

All text respects user’s font-size zoom; use rem units.

Color & Contrast

Default theme: black text on yellow background (or dark mode high-contrast alternative: yellow text on black background).

Use CSS variables for theme; allow user toggles in Settings.

Ensure all UI components maintain ≥4.5:1 contrast ratio; do not rely on color alone—always pair with text labels and TTS.

Icons

Use clear, meaningful SVG icons with aria-hidden="true" and adjacent <span aria-label="...">Label</span>, or include role="img" with aria-label.

Avoid abstract icons; use standard transit symbols (bus, ticket, wallet, settings, help).

Navigation

Top-level navigation or tab bar with clearly labeled items (e.g., “Account”, “Plan Journey”, “Boarding”, “Validation”, “Alerts”, “Support”).

Each navigation item uses a <button> or <a> with aria-label.

Keyboard navigation: focus visible, logical order.

Voice commands: use Web Speech API to listen for commands like “Go to Account”, “Plan journey to hospital”, “Request assistance”. Provide a persistent “Voice Command” activation button.

Onboarding

On first load, run an accessible tutorial:

Automated TTS introduction: “Welcome to TransitAccess. To register, press the Account tab. To plan a journey, press Plan Journey.”

Highlight elements using focus and ARIA live regions announcing context.

Offer skip or repeat instructions.

Provide a persistent “Help” icon to replay onboarding segments.

TTS & Voice Input

Wrap dynamic updates in ARIA live regions (aria-live="polite") so screen readers announce changes.

After any action (e.g., saving a route, purchase confirmation), immediately call speechSynthesis.speak(...) with appropriate locale and content.

For voice input, provide a “Speak now” button; on click, start SpeechRecognition. After recognition: announce “You said: [destination]. Searching routes.”

Handle recognition errors: TTS “Sorry, I did not catch that; please try again.”

Haptic Feedback

Use navigator.vibrate() patterns for key events on supported devices:

Ticket purchase success: short pulse.

Bus arriving soon: long pulse.

Correct bus identified: pattern (e.g., [200,100,200]).

Assistance request confirmed: brief double pulse.

Ensure fallback: if vibration unavailable, include additional TTS confirmation.

Language & Localization

Default English; allow selection of Spanish or French in Settings.

On change: immediately announce “Idioma cambiado a Español” (in Spanish) etc.

Resource files: include all UI strings, TTS prompts, error messages, onboarding text.

Ensure Web Speech API uses correct recognition and synthesis languages per selection.

Offline Support

Cache static assets and saved data (routes, tickets) via Service Worker.

When offline: functionalities that rely on network should gracefully degrade: e.g., “Real-time data unavailable; showing cached schedules.” TTS announcement.

Security & Privacy

Secure storage of user credentials or tokens.

Ask for minimal permissions; clearly announce why geolocation is needed.

Provide Settings control to clear stored data/history.

Testing & Simulation

Include mock mode toggles in Settings:

“Use mock GTFS data” with sample JSON cycling arrival times.

“Simulate boarding assistance responses” to test flow.

“Simulate missed validation” to trigger exception handling.

Provide instructions/comments on using browser dev tools to test screen reader flows (e.g., ChromeVox, NVDA).

Document how to test voice input and TTS in different languages.

Functionalities (High-Level Workflows / Tabs)
1. Account & Subscription Management
Workflow Name: “Account”

Screens/Components:

RegistrationForm:

Voice-driven input: for each field (name, email, password/payment info), provide a “Speak” button activating SpeechRecognition.

Fallback large-text inputs with labels and TTS hints (“Enter your email address”).

After each entry, TTS confirms (“Name set to John Doe”).

ManageSubscriptions:

List available passes/packages: weekly, monthly, concession types. Each item: large text and labeled icon, TTS reads description and price.

Voice command: “Buy monthly pass.” Confirm with TTS: “Monthly pass costs $30; confirm purchase?”

Payment UI: accessible form or integrate a payment widget; after payment, TTS: “Purchase successful; pass valid from today until [date].”

PassWallet:

List active passes/tickets: each entry read via TTS on focus (“You have: monthly pass valid until ...”).

Voice command: “Activate pass” triggers activating that pass for boarding. TTS: “Monthly pass activated.”

Notifications for passes:

Background check: when pass nearing expiration, send in-app Notification API alert; if foreground, use TTS: “Your monthly pass expires tomorrow.” Vibration reminder.

Data & Logic:

Persist user profile and pass details in IndexedDB.

Payment integration: for prototype, simulate via mock endpoint returning success/failure.

Notification scheduling: use Service Worker or setTimeout for near-expiry reminders when app open; for real push, outline integration with Push API.

Accessibility:

All form fields have aria-label and TTS hints.

Keyboard/voice navigation through form.

Error handling: TTS announce errors (“Invalid card number”).

2. Ticket Purchase & Validation
Workflow Name: “Tickets” or part of “Account” if unified.

Screens/Components:

TicketPurchaseScreen:

Voice-based selection: “Single-ride ticket to Zone 2”; show options in list with swipeable focus and TTS.

Buttons large, high-contrast; TTS reads price and confirmation.

DigitalTicketDisplay:

After purchase, generate a QR code or store ticket in IndexedDB/NFC tag if PWA supports.

Also show a TTS-readable ticket ID: e.g., “Ticket ID: ABC123.”

If user asks “Read my ticket ID,” TTS reads it.

OfflineAccess:

Cache ticket data; if offline, allow TTS: “Your ticket is valid until 14:30 today.”

ValidationReminder:

When boarding detected (via geolocation or user tap “Validate”), auto-validate: TTS “Ticket validated.”

If user cannot physically tap reader: a “Notify validator” flow that sends a mock notification to driver/validator: TTS “Validator notified of digital ticket.”

Data & Logic:

Store purchased tickets with validity period.

Boarding detection triggers validation logic (see Check-in below).

Mock endpoint for notifying validator.

Accessibility:

Ensure QR code is complemented by TTS-readable ID so visually impaired can confirm validation.

Voice commands: “Validate ticket now.”

3. Boarding the Correct Vehicle
Workflow Name: “Boarding”

Screens/Components:

PlanJourneyEntryPoint: Link from Plan Journey or directly open Boarding tab which asks user to select a saved journey or enter destination via voice.

DetectVehicleScreen:

“Detect My Bus/Vehicle” button. On press: TTS “Detection started.”

Show status via ARIA live region: “Bus 19 arriving in 2 minutes.”

Vibration patterns for approaching or correct bus.

AssistanceRequest:

Prominent “Request Boarding Assistance” button. On press: call mock API, TTS “Driver notified to assist your boarding.” Vibration confirmation.

After mock response: TTS “Driver acknowledged; be ready to board.”

MissedBoardingFallback:

If detection times out or user indicates missed bus: TTS “Bus departed. Next option: Bus 22 in 7 min. Would you like to switch?” Voice command or button to accept.

Data & Logic:

Use real-time feed (GTFS-RT) or mock: subscribe to updates for selected route and stop.

Geolocation: confirm user is at correct stop; if not, TTS: “You appear not at Stop A; are you at Stop B?”

Assistance request: mock POST to /assist-request with { userId, routeId, stopId, timestamp }. Simulate driver ack after delay.

Accessibility:

ARIA live announcements for each status change.

Voice commands: “Start detection”, “Request assistance”, “Missed bus”.

Ensure “Cancel detection” button accessible at all times.

4. Check-in / Check-out & Exception Handling
Workflow Name: “Validation” or integrated with Boarding and History.

Screens/Components:

AutoCheckScreen:

On boarding detection: automatically attempt check-in; TTS “Checked in on Bus 19.”

On alighting detection via geofencing or user tap “Check out”: TTS “Checked out at Stop X.”

MissedValidationAlert:

If geolocation indicates boarding but no validation: TTS “It seems you boarded without validating. Would you like to report this?”

If user confirms via voice/button: open ReportExceptionScreen.

ReportExceptionScreen:

Voice-driven form: ask “Confirm date?” “Confirm time?” “Confirm route?” After each, TTS repeats. On submit: mock POST to /report-exception. TTS “Your report submitted; you will be informed.”

JourneyHistoryScreen:

List past journeys: each entry read via TTS (“June 10: Bus 19 from A to B; validated successfully”).

For entries with exception: TTS “You reported missed validation on this trip; status: pending.”

Data & Logic:

Geofencing: use Geolocation API, track when user is near stop coordinates.

Validation state stored locally; sync with mock backend.

Exception reports: store in IndexedDB and send when online.

Accessibility:

Announce validation status changes.

Voice commands: “Report missed validation for last trip.”

Clear confirmations and error messages via TTS and vibration on errors/success.

5. Journey Planning & Alternatives
Workflow Name: “Plan Journey”

Screens/Components:

TripWizardScreen:

Voice input: “Plan journey from home to hospital at 10:00 tomorrow.”

On recognition, fetch possible multimodal options via routing API or mock.

Present options as a list with large-text cards; TTS reads summary of each.

Include filters: voice or large-button toggles: “Fewer transfers”, “Low-floor vehicles only.”

On selection: show detailed steps (reuse component from Route Planning), allow saving.

DynamicRerouteEngine:

If user has an active journey and real-time data indicates disruption: TTS “Your bus is delayed. Alternative: Tram 5 departing in 4 min; would you like to switch?”

Button/voice to accept alternative; update journey steps accordingly.

Data & Logic:

Routing API integration or mock.

Real-time data subscription for chosen journey.

User preferences stored for inclusive context.

Accessibility:

ARIA live announcements for reroute suggestions.

Voice commands: “Switch to alternative route.”

6. Notifications & Alerts
Workflow Name: integrated across app; visible in a tab “Alerts” or as in-app notifications.

Features:

Service Disruption Alerts: subscribe to alerts for saved routes; when disruption occurs, use Notification API + TTS: “Line 19 suspended from 3 PM today; plan alternative.”

Personalized Reminders: pass expiry, upcoming journeys (“Your journey to clinic at 2 PM in 30 minutes”).

Emergency Alerts: if severe weather or incidents along route, TTS/vibration: “Severe weather alert on your route; consider postponing travel.”

Implementation:

Use Web Push (mock or real) for background notifications.

When app open, ARIA live announce alerts.

Accessibility:

Ensure notifications are announced by screen readers and accompanied by vibration if critical.

7. Support & Feedback
Workflow Name: “Support”

Screens/Components:

HelpCenterScreen:

Searchable FAQ: text input or voice query (“How to request boarding assistance?”); show list of matching Q&A; TTS reads Q and A on focus.

FeedbackScreen:

After a trip or at any time, user can record voice feedback or fill accessible form: fields labeled and TTS hints.

Options: “Report issue: driver did not stop”, “Report ticket validation failed.” After submission: TTS confirmation.

LiveAssistance:

“Call Support” button triggers phone call link (tel:) or “Chat Support” mock chat interface with TTS prompts guiding user.

Logic:

Mock endpoints for feedback submission.

Store feedback locally if offline, send when online.

Accessibility:

Ensure voice recording control is accessible: labeled “Record feedback”; TTS: “Recording started.”

Announce submission results.

8. Settings & Personalization
Workflow Name: “Settings”

Screens/Components:

LanguageSelection: radio buttons or select list (English, Spanish, French). On change: TTS announcement.

AccessibilityToggles:

Speech rate slider (with TTS preview: “Speech rate set to 1.2x”).

Vibration intensity/pattern options: test button to feel pattern.

Contrast theme selection: high-contrast default, alternative palettes.

Privacy & Data:

Toggle location permission; TTS explains consequences (“Without location, journey planning unavailable”).

Clear stored data: “Clear saved routes and history”; TTS confirmation.

AssistancePreferences:

Predefine boarding assistance notes: text input or voice (“I use wheelchair; need ramp assistance”), TTS confirm.

Manage notification preferences (which alerts to receive).

Mock Mode Toggles (for development/testing):

“Use mock GTFS data”, “Simulate driver response”, “Simulate missed validation”.

Accessibility:

All toggles/buttons labeled with aria-label; TTS announces state changes.

Keyboard and voice navigation through settings.

Additional Implementation Details
Routing & Real-Time Integration:

Provide abstraction layer: TransitService with methods: fetchRoutes(origin, destination), subscribeRealTime(routeId, stopId), fetchAlerts(). Implement both real and mock versions.

Voice & TTS Service:

VoiceService to wrap Web Speech API for recognition; TTSService to wrap SpeechSynthesis. Ensure language matches Settings.

Geolocation & Validation:

LocationService monitors position; triggers check-in/out logic. Include permission handling and TTS explanations.

Notification Service:

Wrap Notification API; request permission; handle foreground vs background.

Data Persistence:

Use IndexedDB for complex data (journey history, saved routes, tickets). Provide utility hooks or context for CRUD operations.

Accessibility Utilities:

Custom hook useAnnounce(text: string) that inserts into an ARIA live region and calls TTS.

Ensure focus management: after navigation or modal open, call element.focus(), then useAnnounce so screen reader reads context.

Error Handling & Fallbacks:

If Web Speech API unsupported: fallback to text input with TTS guidance.

If Vibration API unsupported: always provide TTS confirmation.

If geolocation unavailable: prompt user to enter stop manually.

PWA & Offline:

Service Worker caches static assets and saved data; when offline, notify user via TTS: “You are offline; some features disabled.”

Offline queue: store actions (e.g., exception report) and sync when online.

Internationalization:

Use react-i18next with namespaces for UI, TTS prompts, error messages, onboarding text. Ensure text keys and translations cover all content.

Testing & Documentation:

Include comments in code explaining accessibility justifications: e.g.,

tsx
Kopyala
Düzenle
<button 
  aria-label={t('detectBusButtonLabel')} 
  onClick={startDetection}
>
  {t('detectBus')}
</button>
// Justification: voice label ensures screen reader announces “Detect My Bus” clearly.
Add README or inline docs: how to test voice input, mock data toggles, screen reader guidelines.

Deliverables
Full React project scaffold with the above structure: components, contexts/services, hooks, styling, PWA config.

Resource files for English/Spanish/French.

Mock data files (GTFS-RT JSON samples, driver response simulation).

Service Worker setup for offline.

Accessibility utilities and examples of ARIA live regions.

Onboarding flow code demonstrating TTS-driven tutorial.

Testing instructions: how to run in browser/mobile, enable screen reader, simulate geolocation and real-time updates.

Comments/Documentation throughout explaining design choices and justifications for visually impaired users (reducing cognitive load, ensuring independence, addressing barriers).

📝 Note to Replit AI: Generate clear, modular code that maps each high-level task to distinct screens or workflows. Use React best practices and web APIs for voice, TTS, geolocation, vibration, notifications, and PWA. Ensure all UI components are semantic, keyboard/voice navigable, and announce changes via ARIA live and SpeechSynthesis. Apply high-contrast theming, scalable fonts, and multilingual support. Include mock services and toggles for development. Structure code so developers can easily replace mock endpoints with real transit APIs or backend services. Prioritize usability and independence for visually impaired users over visual complexity.